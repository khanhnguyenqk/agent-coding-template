{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "\n",
    "api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"Anthropic API key not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "\n",
    "# Define the directory where templates reside\n",
    "template_dir = \"/Users/khannguyen/projects/agent-coding-template/src/agent_coding_template/templates\"\n",
    "# Create a Jinja2 environment with a file system loader\n",
    "env = Environment(loader=FileSystemLoader(template_dir))\n",
    "# Load the template file\n",
    "template = env.get_template(\"repo_prompt_template.j2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content=[{'text': \"I'll help you understand what this code repository is about. Let me check the README file first to get an overview.\", 'type': 'text'}, {'id': 'toolu_01CUb6jA6LZXmf2cbQJzHPcT', 'input': {'directory': '/Users/khannguyen/projects/evaluations/ToolTalk'}, 'name': 'ReadmeReaderTool', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01395U2oboJeCunX8TGYPc4i', 'model': 'claude-3-5-sonnet-20241022', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 841, 'output_tokens': 97}}, id='run-6111dd98-2c95-4671-bdd7-fac4bbb21f3c-0', tool_calls=[{'name': 'ReadmeReaderTool', 'args': {'directory': '/Users/khannguyen/projects/evaluations/ToolTalk'}, 'id': 'toolu_01CUb6jA6LZXmf2cbQJzHPcT', 'type': 'tool_call'}], usage_metadata={'input_tokens': 841, 'output_tokens': 97, 'total_tokens': 938, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='# :wrench: ToolTalk :speech_balloon:\\n\\n<p align=\"center\">\\n   <a href=\"https://arxiv.org/abs/2311.10775\" target=\"_blank\">:page_facing_up: Paper</a> | <a href=\"mailto:tooltalk@service.microsoft.com\" target=\"_blank\">:mailbox: Contact</a>\\n</p>\\n\\nIntroducing ToolTalk a benchmark for evaluating Tool LLMs in a conversational setting.\\n\\n## Details\\n\\n<div align=\"center\">\\n\\t<img src=\"images/Evaluation.png\" width=90% />\\n</div>\\n\\nToolTalk is designed to evaluate tool-augmented LLMs as a chatbot,\\nan increasingly popular paradigm for everyday users to harness the power of LLMs.\\nToolTalk contains a handcrafted dataset of 28 easy conversations and 50 hard conversations.\\nWe annotate these conversations to contain a ground truth usage of 28 unique tools belonging to 7 themed \"plugins\".\\n\\nEvaluation consists of prompting an LLM to predict the correct sequence of tools after every user utterance in a conversation.\\nThus, evaluating on a single conversation requires an LLM to correctly predict multiple sub-tasks.\\nPredictions are compared against the ground truth to determine success for a single conversation.\\n\\nWe evaluate two chatbots on ToolTalk powered by gpt-3.5-turbo-0613 and gpt-4-0613 implemented by using the chat completions API from OpenAI.\\n\\n| Model   | ToolTalk | Success rate | Precision | Recall | Incorrect Action Rate |\\n|---------|----------|--------------|-----------|--------|-----------------------|\\n| GPT-3.5 | Easy     | 85.7%        | 42.4%     | 89.3%  | 5.0%                  |\\n| GPT-4   | Easy     | 92.8%        | 69.2%     | 96.4%  | 3.8%                  |\\n| GPT-3.5 | Hard     | 26.0%        | 54.6%     | 69.7%  | 23.9%                 |\\n| GPT-4   | Hard     | 50.0%        | 74.9%     | 79.0%  | 25.1%                 |\\n\\n## Setup\\n\\nToolTalk can be setup using the following commands. Install local package with dev dependencies to enable unit tests.\\n\\n```bash\\npip install -r requirements.txt\\npip install -e \".[dev]\"\\n```\\n\\nTo verify that the installation was successful, run the unit tests.\\n\\n```bash\\npytest tests\\n```\\n\\n## Reproducing the results\\n\\nThe results on GPT-3.5-turbo and GPT-4 can be reproduced using the following commands. This requires having access to \\nOpenAI\\'s API. The results will be saved in the `results` folder. The script caches intermediary results, so it can be \\nre-run if it is interrupted for any reason.\\n\\n```bash\\nexport OPENAI_API_KEY=<your key>\\nbash evaluate_gpt35turbo.sh\\nbash evaluate_gpt4.sh\\n```\\n\\nYour results should look something like the number above, there will be some variance due to both models having non-deterministic results.\\n\\n## Generating scenarios\\n\\nTo generate new scenarios, you can use the following command.\\n\\n```bash\\npython -m tooltalk.generation.scenario_generator --prompt src/prompts/scenario_template.md --output_dir output/scenarios\\n```\\n\\n## Evaluating on new models\\n\\nThe easiest way to evaluate on new models would be to create a new `Predictor` class that inherits from `tooltalk.evaluation.tool_executor.BaseAPIPredictor`.\\nFor an example of how to do this, see `tooltalk.evaluation.tool_executor.GPT3Predictor` and `tooltalk.evaluation.evaluate_openai.OpenAIPredictor`.\\n\\n## Citing\\n\\n```\\n@article{farn2023tooltalk,\\n  title={ToolTalk: Evaluating Tool-Usage in a Conversation Setting},\\n  author={Nicholas Farn and Richard Shin},\\n  year={2023},\\n  journal={arXiv preprint arXiv:2311.10775},\\n}\\n```\\n\\n## Contributing\\n\\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\\n\\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\\nprovided by the bot. You will only need to do this once across all repos using our CLA.\\n\\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\\n\\n## Trademarks\\n\\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft \\ntrademarks or logos is subject to and must follow \\n[Microsoft\\'s Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).\\nUse of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.\\nAny use of third-party trademarks or logos are subject to those third-party\\'s policies.\\n', name='ReadmeReaderTool', id='6e38e382-e005-4c95-bd64-d0161a19d0cc', tool_call_id='toolu_01CUb6jA6LZXmf2cbQJzHPcT')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content='Let me help explain what this repository is about:\\n\\nToolTalk is a benchmark created to evaluate Tool-augmented Large Language Models (LLMs) in a conversational setting. Here are the key points about the repository:\\n\\n1. Purpose:\\n- It\\'s designed to evaluate how well LLMs can use tools while acting as a chatbot\\n- The benchmark tests the LLM\\'s ability to predict the correct sequence of tools in response to user conversations\\n\\n2. Dataset:\\n- Contains 28 easy conversations and 50 hard conversations\\n- Includes annotations for 28 unique tools spread across 7 themed \"plugins\"\\n- Each conversation requires multiple sub-tasks to be completed correctly\\n\\n3. Evaluation Results:\\n- The benchmark has been tested with GPT-3.5-turbo and GPT-4\\n- GPT-4 performs better overall:\\n  - On easy conversations: 92.8% success rate\\n  - On hard conversations: 50.0% success rate\\n- GPT-3.5 performance:\\n  - On easy conversations: 85.7% success rate\\n  - On hard conversations: 26.0% success rate\\n\\n4. Implementation:\\n- The repository includes code to:\\n  - Set up and run the benchmark\\n  - Generate new scenarios\\n  - Evaluate different models\\n  - Reproduce results with GPT-3.5-turbo and GPT-4\\n\\n5. Usage:\\n- Can be installed using pip\\n- Requires OpenAI API access for reproducing results\\n- Supports creating custom evaluations for new models\\n- Includes unit tests to verify installation\\n\\nThis is an open-source project from Microsoft, welcoming contributions and following Microsoft\\'s Open Source Code of Conduct. It represents a significant contribution to understanding and evaluating how well LLMs can use tools in conversational contexts.', additional_kwargs={}, response_metadata={'id': 'msg_01Bvq4cbSQdMNbLnkZDV36xC', 'model': 'claude-3-5-sonnet-20241022', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 2305, 'output_tokens': 409}}, id='run-299f3c8a-ffe4-45ca-b171-eba80761a679-0', usage_metadata={'input_tokens': 2305, 'output_tokens': 409, 'total_tokens': 2714, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# Import relevant functionality\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "from agent_coding_template.tools import *\n",
    "\n",
    "# Create the agent\n",
    "memory = MemorySaver()\n",
    "model = ChatAnthropic(model_name=\"claude-3-5-sonnet-20241022\")\n",
    "tools = [DirectoryMapperTool(), FileReaderTool(), ReadmeReaderTool()]\n",
    "agent_executor = create_react_agent(model, tools, checkpointer=memory)\n",
    "\n",
    "# Use the agent\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=template.render(repo_dir=\"/Users/khannguyen/projects/evaluations/ToolTalk\"))]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content=[{'text': 'Let me check the repository structure to find the relevant implementation files that you would need to adapt.', 'type': 'text'}, {'id': 'toolu_01Ls3Miae7Zj3y1FK4vBAM3g', 'input': {'directory': '/Users/khannguyen/projects/evaluations/ToolTalk'}, 'name': 'DirectoryMapperTool', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01LpEU2A3h3EoKMFWTuVGAPM', 'model': 'claude-3-5-sonnet-20241022', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 2734, 'output_tokens': 92}}, id='run-f4cb54fa-6298-4e38-a880-4ff6164827c3-0', tool_calls=[{'name': 'DirectoryMapperTool', 'args': {'directory': '/Users/khannguyen/projects/evaluations/ToolTalk'}, 'id': 'toolu_01Ls3Miae7Zj3y1FK4vBAM3g', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2734, 'output_tokens': 92, 'total_tokens': 2826, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='ToolTalk/\\n├── CODE_OF_CONDUCT.md\\n├── CONTRIBUTING.md\\n├── LICENSE\\n├── NOTICE\\n├── README.md\\n├── SECURITY.md\\n├── SUPPORT.md\\n├── data/\\n│   ├── databases/\\n│   │   ├── Account.json\\n│   │   ├── Alarm.json\\n│   │   ├── Calendar.json\\n│   │   ├── Email.json\\n│   │   ├── HistoricWeather.json\\n│   │   ├── Message.json\\n│   │   ├── Reminder.json\\n│   │   └── Weather.json\\n│   ├── easy/\\n│   │   ├── AddAlarm-easy.json\\n│   │   ├── AddReminder-easy.json\\n│   │   ├── ChangePassword-easy.json\\n│   │   ├── CompleteReminder-easy.json\\n│   │   ├── CreateEvent-easy.json\\n│   │   ├── CurrentWeather-easy.json\\n│   │   ├── DeleteAccount-easy.json\\n│   │   ├── DeleteAlarm-easy.json\\n│   │   ├── DeleteEvent-easy.json\\n│   │   ├── DeleteReminder-easy.json\\n│   │   ├── FindAlarms-easy.json\\n│   │   ├── ForecastWeather-easy.json\\n│   │   ├── GetAccountInformation-easy.json\\n│   │   ├── GetReminders-easy.json\\n│   │   ├── HistoricWeather-easy.json\\n│   │   ├── LogoutUser-easy.json\\n│   │   ├── ModifyEvent-easy.json\\n│   │   ├── QueryCalendar-easy.json\\n│   │   ├── QueryUser-easy.json\\n│   │   ├── RegisterUser-easy.json\\n│   │   ├── ResetPassword-easy.json\\n│   │   ├── SearchInbox-easy.json\\n│   │   ├── SearchMessages-easy.json\\n│   │   ├── SendEmail-easy.json\\n│   │   ├── SendMessage-easy.json\\n│   │   ├── SendVerificationCode-easy.json\\n│   │   ├── UpdateAccountInformation-easy.json\\n│   │   └── UserLogin-easy.json\\n│   └── tooltalk/\\n│       ├── AccountTools-Alarm-Calendar-AddAlarm-0.json\\n│       ├── AccountTools-Alarm-Email-GetAccountInformati-0.json\\n│       ├── AccountTools-Alarm-Messages-FindAlarm-0.json\\n│       ├── AccountTools-Alarm-Weather-DeleteAccount-2.json\\n│       ├── AccountTools-Calendar-Weather-RegisterUser-0.json\\n│       ├── AccountTools-Email-Reminder-ChangePassword-1.json\\n│       ├── Alarm-Calendar-Email-DeleteAlarm-1.json\\n│       ├── Alarm-Calendar-Messages-AddAlarm-1.json\\n│       ├── Alarm-Messages-Reminder-GetReminder-2.json\\n│       ├── Alarm-Reminder-Weather-AddReminder-1.json\\n│       ├── Alarm-Reminder-Weather-DeleteAlarm-2.json\\n│       ├── Alarm-Reminder-Weather-FindAlarm-2.json\\n│       ├── Calendar-Email-Reminder-GetReminder-1.json\\n│       ├── Calendar-Email-Reminder-SendEmail-2.json\\n│       ├── Calendar-Messages-Reminder-AddReminder-1.json\\n│       ├── Calendar-Messages-Reminder-CreateEvent-1.json\\n│       ├── Calendar-Messages-Reminder-ModifyEvent-0.json\\n│       ├── Calendar-Messages-Reminder-QueryCalendar-2.json\\n│       ├── Calendar-Messages-Weather-DeleteEvent-0.json\\n│       ├── Calendar-Messages-Weather-SendMessage-0.json\\n│       ├── Calendar-Messages-Weather-SendMessage-1.json\\n│       ├── Calendar-Reminder-Weather-CompleteReminder-1.json\\n│       ├── Calendar-Reminder-Weather-CreateEvent-1.json\\n│       ├── Calendar-Reminder-Weather-DeleteEvent-0.json\\n│       ├── Calendar-Reminder-Weather-DeleteReminder-1.json\\n│       ├── Calendar-Reminder-Weather-ModifyEvent-0.json\\n│       ├── Calendar-Reminder-Weather-ModifyEvent-1.json\\n│       ├── Calendar-Reminder-Weather-QueryCalendar-0.json\\n│       ├── Email-Messages-Reminder-DeleteReminder-1.json\\n│       ├── Email-Messages-Reminder-SearchMessage-1.json\\n│       ├── Email-Messages-Reminder-SendEmail-2.json\\n│       ├── Email-Messages-Reminder-SendMessage-2.json\\n│       ├── Email-Messages-Weather-SendMessage-2.json\\n│       ├── Email-Reminder-Weather-CompleteReminder-2.json\\n│       ├── Email-Reminder-Weather-DeleteReminder-0.json\\n│       ├── Email-Reminder-Weather-GetReminder-0.json\\n│       ├── Email-Reminder-Weather-SearchInbox-1.json\\n│       ├── Email-Reminder-Weather-SendEmail-2.json\\n│       ├── Messages-Reminder-Weather-AddReminder-1.json\\n│       ├── Messages-Reminder-Weather-CompleteReminder-1.json\\n│       ├── Messages-Reminder-Weather-ForecastWeather-1.json\\n│       ├── Messages-Reminder-Weather-GetReminder-0.json\\n│       ├── Messages-Reminder-Weather-SearchMessage-2.json\\n│       ├── Messages-Reminder-Weather-SendMessage-2.json\\n│       ├── golden_conversation_1.json\\n│       ├── golden_conversation_2.json\\n│       ├── golden_conversation_3.json\\n│       ├── golden_conversation_4.json\\n│       ├── golden_conversation_5.json\\n│       └── golden_conversation_6.json\\n├── images/\\n│   └── Evaluation.png\\n├── output/\\n│   └── nvdev/\\n│       └── meta/\\n│           ├── llama-3.1-70b-instruct/\\n│           │   ├── AddAlarm-easy.json\\n│           │   ├── AddReminder-easy.json\\n│           │   ├── ChangePassword-easy.json\\n│           │   ├── CompleteReminder-easy.json\\n│           │   ├── CreateEvent-easy.json\\n│           │   ├── CurrentWeather-easy.json\\n│           │   ├── DeleteAccount-easy.json\\n│           │   ├── DeleteAlarm-easy.json\\n│           │   ├── DeleteEvent-easy.json\\n│           │   ├── DeleteReminder-easy.json\\n│           │   ├── FindAlarms-easy.json\\n│           │   ├── ForecastWeather-easy.json\\n│           │   ├── GetAccountInformation-easy.json\\n│           │   ├── GetReminders-easy.json\\n│           │   ├── HistoricWeather-easy.json\\n│           │   ├── LogoutUser-easy.json\\n│           │   ├── ModifyEvent-easy.json\\n│           │   ├── QueryCalendar-easy.json\\n│           │   ├── QueryUser-easy.json\\n│           │   ├── RegisterUser-easy.json\\n│           │   ├── ResetPassword-easy.json\\n│           │   ├── SearchInbox-easy.json\\n│           │   ├── SearchMessages-easy.json\\n│           │   ├── SendEmail-easy.json\\n│           │   ├── SendMessage-easy.json\\n│           │   ├── SendVerificationCode-easy.json\\n│           │   ├── UpdateAccountInformation-easy.json\\n│           │   ├── UserLogin-easy.json\\n│           │   └── metrics.json\\n│           └── llama-3.1-70b-instruct2/\\n├── requirements.txt\\n├── scripts/\\n│   ├── evaluate_gpt35turbo.sh\\n│   └── evaluate_gpt4.sh\\n├── setup.cfg\\n├── setup.py\\n├── src/\\n│   ├── __init__.py\\n│   ├── prompts/\\n│   │   └── scenario_template.md\\n│   ├── scripts/\\n│   │   ├── fix_apis_used.py\\n│   │   └── refactor_tool_talk.py\\n│   ├── tooltalk/\\n│   │   ├── __init__.py\\n│   │   ├── __pycache__/\\n│   │   │   └── __init__.cpython-312.pyc\\n│   │   ├── apis/\\n│   │   │   ├── __init__.py\\n│   │   │   ├── __pycache__/\\n│   │   │   │   ├── __init__.cpython-312.pyc\\n│   │   │   │   ├── account.cpython-312.pyc\\n│   │   │   │   ├── alarm.cpython-312.pyc\\n│   │   │   │   ├── api.cpython-312.pyc\\n│   │   │   │   ├── calendar.cpython-312.pyc\\n│   │   │   │   ├── email.cpython-312.pyc\\n│   │   │   │   ├── exceptions.cpython-312.pyc\\n│   │   │   │   ├── message.cpython-312.pyc\\n│   │   │   │   ├── reminder.cpython-312.pyc\\n│   │   │   │   ├── utils.cpython-312.pyc\\n│   │   │   │   └── weather.cpython-312.pyc\\n│   │   │   ├── account.py\\n│   │   │   ├── alarm.py\\n│   │   │   ├── api.py\\n│   │   │   ├── calendar.py\\n│   │   │   ├── email.py\\n│   │   │   ├── exceptions.py\\n│   │   │   ├── message.py\\n│   │   │   ├── reminder.py\\n│   │   │   ├── utils.py\\n│   │   │   └── weather.py\\n│   │   ├── evaluation/\\n│   │   │   ├── __init__.py\\n│   │   │   ├── __pycache__/\\n│   │   │   │   ├── __init__.cpython-312.pyc\\n│   │   │   │   └── tool_executor.cpython-312.pyc\\n│   │   │   ├── calculate_error_types.py\\n│   │   │   ├── evaluate_nim.py\\n│   │   │   ├── evaluate_openai.py\\n│   │   │   └── tool_executor.py\\n│   │   ├── generation/\\n│   │   │   ├── __init__.py\\n│   │   │   └── scenario_generator.py\\n│   │   ├── llm_clients/\\n│   │   └── utils/\\n│   │       ├── __init__.py\\n│   │       ├── __pycache__/\\n│   │       │   ├── __init__.cpython-312.pyc\\n│   │       │   ├── file_utils.cpython-312.pyc\\n│   │       │   └── openai_utils.cpython-312.pyc\\n│   │       ├── file_utils.py\\n│   │       └── openai_utils.py\\n│   └── tooltalk.egg-info/\\n│       ├── PKG-INFO\\n│       ├── SOURCES.txt\\n│       ├── dependency_links.txt\\n│       ├── requires.txt\\n│       └── top_level.txt\\n└── tests/\\n    ├── __pycache__/\\n    │   ├── test_documentation.cpython-312-pytest-7.4.4.pyc\\n    │   ├── test_documentation.cpython-312-pytest-8.3.4.pyc\\n    │   ├── test_oracle.cpython-312-pytest-7.4.4.pyc\\n    │   └── test_oracle.cpython-312-pytest-8.3.4.pyc\\n    ├── test_documentation.py\\n    └── test_oracle.py', name='DirectoryMapperTool', id='2d2bc4b6-9c5d-4c99-945d-756c22324dcc', tool_call_id='toolu_01Ls3Miae7Zj3y1FK4vBAM3g')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content=[{'text': 'Let me check the implementation of the tool executor to understand how to adapt it.', 'type': 'text'}, {'id': 'toolu_01KU51CYPqL4ksLJ7vkuZ9ZK', 'input': {'file_path': '/Users/khannguyen/projects/evaluations/ToolTalk/src/tooltalk/evaluation/tool_executor.py'}, 'name': 'FileReaderTool', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01TCUBWJbkRux6uQ2LLMPy2G', 'model': 'claude-3-5-sonnet-20241022', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 5988, 'output_tokens': 104}}, id='run-462048b6-e8f7-4976-899c-0ca5e4a5c204-0', tool_calls=[{'name': 'FileReaderTool', 'args': {'file_path': '/Users/khannguyen/projects/evaluations/ToolTalk/src/tooltalk/evaluation/tool_executor.py'}, 'id': 'toolu_01KU51CYPqL4ksLJ7vkuZ9ZK', 'type': 'tool_call'}], usage_metadata={'input_tokens': 5988, 'output_tokens': 104, 'total_tokens': 6092, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='\"\"\"\\nCopyright (c) Microsoft Corporation.\\nLicensed under the MIT license.\\n\"\"\"\\nimport json\\nimport logging\\nimport os\\nfrom typing import List\\nfrom datetime import datetime\\nfrom collections import deque\\nfrom abc import ABC, abstractmethod\\n\\nfrom tooltalk.apis import ALL_APIS\\nfrom tooltalk.apis.account import ACCOUNT_DB_NAME, DeleteAccount, UserLogin, LogoutUser, RegisterUser\\nfrom tooltalk.utils.file_utils import get_names_and_paths\\n\\nlogger = logging.getLogger(__name__)\\n\\n\\nclass ToolExecutor:\\n    \"\"\"\\n    Handles execution of tools and maintains state of databases when simulating conversations.\\n    \"\"\"\\n    def __init__(\\n            self,\\n            init_database_dir: str = None,\\n            ignore_list: List[str] = None,\\n            account_database: str = ACCOUNT_DB_NAME,\\n    ) -> None:\\n        self.databases = dict()\\n        self.database_files = dict()\\n        self.account_database = account_database\\n        self.ignore_list = ignore_list if ignore_list is not None else list()\\n        self.session_token = None\\n\\n        for file_name, file_path in get_names_and_paths(init_database_dir):\\n            database_name, ext = os.path.splitext(file_name)\\n            if ext == \".json\":\\n                self.database_files[database_name] = file_path\\n                with open(file_path, \\'r\\', encoding=\\'utf-8\\') as reader:\\n                    self.databases[database_name] = json.load(reader)\\n        if self.account_database not in self.databases:\\n            raise ValueError(f\"Account database {self.account_database} not found\")\\n\\n        self.apis = {api.__name__: api for api in ALL_APIS if api.__name__ not in self.ignore_list}\\n        self.inited_tools = dict()\\n        self.now_timestamp = None\\n\\n    def reset_executor(self):\\n        \"\"\"\\n        Reset all tools and databases to their initial state.\\n        \"\"\"\\n        self.databases = dict()\\n        for database_name, file_path in self.database_files.items():\\n            with open(file_path, \\'r\\', encoding=\\'utf-8\\') as reader:\\n                self.databases[database_name] = json.load(reader)\\n        self.inited_tools = dict()\\n        self.now_timestamp = None\\n        self.session_token = None\\n\\n    def get_init_tool(self, tool_name: str):\\n        if tool_name in self.inited_tools:\\n            return self.inited_tools[tool_name]\\n        cls = self.apis[tool_name]\\n        account_db = self.databases.get(self.account_database)\\n        if cls.database_name is not None:\\n            database = self.databases.get(cls.database_name)\\n            tool = cls(\\n                account_database=account_db,\\n                now_timestamp=self.now_timestamp,\\n                api_database=database,\\n            )\\n        else:\\n            tool = cls(\\n                account_database=account_db,\\n                now_timestamp=self.now_timestamp,\\n            )\\n\\n        self.inited_tools[tool_name] = tool\\n        return tool\\n\\n    def execute_tool(self, api_name: str, parameters: dict):\\n        request = {\\n            \"api_name\": api_name,\\n            \"parameters\": parameters\\n        }\\n        if api_name not in self.apis:\\n            response = {\\n                \"response\": None,\\n                \"exception\": f\"API {api_name} not found\"\\n            }\\n            return request, response\\n\\n        tool = self.get_init_tool(api_name)\\n        if tool.requires_auth:\\n            if self.session_token is None:\\n                response = {\\n                    \"response\": None,\\n                    \"exception\": \"User is not logged in\"\\n                }\\n                return request, response\\n            parameters[\"session_token\"] = self.session_token\\n        if api_name in [UserLogin.__name__, RegisterUser.__name__] and self.session_token is not None:\\n            username = tool.check_session_token(self.session_token)[\"username\"]\\n            response = {\\n                \"response\": None,\\n                \"exception\": f\"Only one user can be logged in at a time. Current user is {username}.\",\\n            }\\n            return request, response\\n\\n        # execute tool\\n        response = tool(**parameters)\\n\\n        # capture session_token and simulate login and logout\\n        if api_name in [UserLogin.__name__, RegisterUser.__name__] and response[\"exception\"] is None:\\n            self.session_token = response[\"response\"][\"session_token\"]\\n        elif api_name in [LogoutUser.__name__, DeleteAccount.__name__] and response[\"exception\"] is None:\\n            self.session_token = None\\n        return request, response\\n\\n    def compare_api_calls(self, prediction: dict, ground_truth: dict) -> bool:\\n        api_name = prediction[\"request\"][\"api_name\"]\\n        if api_name != ground_truth[\"request\"][\"api_name\"]:\\n            return False\\n\\n        # TODO add session_token if ground truth needs it\\n        return self.apis[api_name].check_api_call_correctness(prediction, ground_truth)\\n\\n    def is_action(self, api_name: str) -> bool:\\n        if api_name not in self.apis:\\n            return False\\n        return self.apis[api_name].is_action\\n\\n    def evaluate_predictions(self, conversation_with_predictions: dict) -> dict:\\n        \"\"\"\\n        Compare predictions in a conversation with complete ground truth in conversation returning metrics.\\n        Calculates recall over ground truth, where predictions can only match to function in ground truth once.\\n        Additionally, calculates action precision, number of actions that match ground truth.\\n        Finally, calculates success, which is recall == 1.0 and action precision == 1.0.\\n\\n        Metrics:\\n            predictions: number of predictions\\n            ground_truths: number of ground truths\\n            matches: number of predictions that match ground truth\\n            actions: number of predictions that are actions\\n            valid_actions: number of actions that match ground truth\\n            bad_actions: number of actions that don\\'t match ground truth\\n            precision: matches / predictions\\n            recall: matches / ground_truths\\n            action_precision: valid_actions / actions\\n            bad_action_rate: bad_actions / actions\\n            success: recall == 1.0 and bad_action_rate == 0.0\\n        \"\"\"\\n        predictions = list()\\n        ground_truths = list()\\n        for turn in conversation_with_predictions[\"conversation\"]:\\n            if turn[\"role\"] == \"User\":\\n                continue\\n            if \"predictions\" in turn:\\n                # last prediction will be assistant response\\n                for prediction in turn[\"predictions\"]:\\n                    if prediction[\\'role\\'] == \\'api\\':\\n                        predictions.append(prediction)\\n            if \"apis\" in turn:\\n                ground_truths.extend(turn[\"apis\"])\\n\\n        # remove ground truth as they get matched to predictions\\n        match_count = 0\\n        action_count = 0\\n        valid_action_count = 0\\n        bad_action_count = 0\\n        current_ground_truths = deque(ground_truths)\\n        for prediction in predictions:\\n            is_match = False\\n            new_ground_truths = deque()\\n            while current_ground_truths:\\n                ground_truth = current_ground_truths.popleft()\\n                if self.compare_api_calls(prediction, ground_truth):\\n                    # don\\'t add back in ground truth that matches\\n                    is_match = True\\n                    ground_truth[\"match\"] = True\\n                    break\\n                else:\\n                    new_ground_truths.append(ground_truth)\\n            else:\\n                logger.debug(f\"Failed {json.dumps(prediction, indent=4)}\")\\n\\n            # alter prediction data\\n            is_action = self.is_action(prediction[\"request\"][\"api_name\"])\\n            is_successful = prediction[\"exception\"] is None\\n            is_bad_action = not is_match and is_action and is_successful\\n            prediction[\"match\"] = is_match\\n            prediction[\"bad_action\"] = is_bad_action\\n\\n            # add back in ground truths that don\\'t match\\n            while current_ground_truths:\\n                new_ground_truths.append(current_ground_truths.popleft())\\n            current_ground_truths = new_ground_truths\\n\\n            # update counters\\n            match_count += is_match\\n            action_count += is_action\\n            valid_action_count += is_action and is_match\\n            bad_action_count += is_bad_action\\n\\n        for ground_truth in current_ground_truths:\\n            ground_truth[\"match\"] = False\\n\\n        precision = match_count / len(predictions) if len(predictions) > 0 else 0\\n        recall = match_count / len(ground_truths)\\n        action_precision = valid_action_count / action_count if action_count > 0 else 1\\n        bad_action_rate = bad_action_count / action_count if action_count > 0 else 0\\n        success = recall == 1.0 and bad_action_rate == 0.0\\n        soft_success = recall * (1.0 - bad_action_rate)\\n        metrics = {\\n            \"predictions\": len(predictions),\\n            \"ground_truths\": len(ground_truths),\\n            \"matches\": match_count,\\n            \"actions\": action_count,\\n            \"valid_actions\": valid_action_count,\\n            \"bad_actions\": bad_action_count,\\n            \"precision\": precision,\\n            \"recall\": recall,\\n            \"action_precision\": action_precision,\\n            # number of actions matching ground truth\\n            \"bad_action_rate\": bad_action_rate,\\n            # how often an action is bad aka successful but not matching ground truth\\n            \"success\": success,\\n            \"soft_success\": soft_success,\\n        }\\n        conversation_with_predictions[\"metrics\"] = metrics\\n        return conversation_with_predictions\\n\\n    def init_conversation_state(self, metadata: dict, api_history: list, user_data: dict = None) -> None:\\n        self.reset_executor()\\n        self.now_timestamp = datetime.strptime(metadata[\"timestamp\"], \"%Y-%m-%d %H:%M:%S\")\\n\\n        # setting these should never fail, if it does it\\'s a bug in the dataset\\n        if \"session_token\" in user_data:\\n            username = user_data[\"username\"]\\n            self.session_token = user_data[\"session_token\"]\\n            self.databases[self.account_database][username][\"session_token\"] = user_data[\"session_token\"]\\n        if \"verification_code\" in user_data:\\n            username = user_data[\"username\"]\\n            self.databases[self.account_database][username][\"verification_code\"] = user_data[\"verification_code\"]\\n\\n        for api in api_history:\\n            # this should also never fail, if it does it\\'s a bug in dataset\\n            self.execute_tool(**api[\"request\"])\\n\\n    def run_conversation(self, conversation: dict, predict_func: callable):\\n        \"\"\"\\n        Simulates a conversation, calling prediction function\\n        \"\"\"\\n        metadata = conversation[\"metadata\"]\\n        user_data = conversation.get(\"user\")\\n        ground_truth_history = list()\\n        api_history = list()\\n\\n        for turn in conversation[\"conversation\"]:\\n            if turn[\"role\"] == \"user\":\\n                ground_truth_history.append({\\n                    \"role\": \"user\",\\n                    \"text\": turn[\"text\"]\\n                })\\n                continue\\n\\n            if turn[\"role\"] != \"assistant\":\\n                raise ValueError(f\"turn role must be user or assistant, instead got {turn[\\'role\\']}\")\\n\\n            # other turns should be the assistant and could contain API calls\\n            self.init_conversation_state(metadata, api_history, user_data)\\n            predictions = list()\\n            current_history = ground_truth_history.copy()\\n            while True:\\n                prediction = predict_func(metadata, current_history)\\n                if prediction[\"role\"] == \"assistant\":\\n                    # done with predicting apis\\n                    predictions.append(prediction)\\n                    break\\n                elif prediction[\"role\"] == \"api\":\\n                    # execute api call\\n                    if prediction[\"request\"][\"parameters\"] is None:\\n                        request = prediction[\"request\"]\\n                        response = {\\n                            \"response\": None,\\n                            \"exception\": \"Failed to parse API call\"\\n                        }\\n                    else:\\n                        request, response = self.execute_tool(**prediction[\"request\"])\\n                    prediction_and_response = {\\n                        \"request\": request,\\n                        \"response\": response[\"response\"],\\n                        \"exception\": response[\"exception\"],\\n                        \"metadata\": prediction.get(\"metadata\")\\n                    }\\n                    predictions.append(prediction_and_response)\\n                    prediction_and_response[\"role\"] = \"api\"\\n                    current_history.append(prediction_and_response)\\n                else:\\n                    raise ValueError(f\"prediction role should be api or assistant, instead got {prediction[\\'role\\']}\")\\n\\n            # add predictions to original conversation object\\n            turn[\"predictions\"] = predictions\\n            if \"apis\" in turn:\\n                for api in turn[\"apis\"]:\\n                    api_history.append(api)\\n                    ground_truth_history.append({\\n                        \"role\": \"api\",\\n                        \"request\": api[\"request\"],\\n                        \"response\": api[\"response\"],\\n                        \"exception\": api[\"exception\"]\\n                    })\\n            ground_truth_history.append({\\n                \"role\": \"assistant\",\\n                \"text\": turn[\"text\"]\\n            })\\n\\n        return conversation\\n\\n\\nclass BaseAPIPredictor(ABC):\\n    @abstractmethod\\n    def __init__(self, function_docs: List[dict], *args, **kwargs):\\n        raise NotImplementedError\\n\\n    @abstractmethod\\n    def predict(self, metadata: dict, conversation_history: dict) -> dict:\\n        raise NotImplementedError\\n\\n    def __call__(self, metadata: dict, conversation_history: dict) -> dict:\\n        \"\"\"Simple wrapper for convenience.\"\"\"\\n        return self.predict(metadata, conversation_history)\\n', name='FileReaderTool', id='04a0695c-8df7-40ab-9538-73cc5a7dd86c', tool_call_id='toolu_01KU51CYPqL4ksLJ7vkuZ9ZK')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content='Based on the code examination, here\\'s how you would adapt ToolTalk to your programmatic interface:\\n\\n1. Create a Custom Predictor:\\nThe main integration point is through the `BaseAPIPredictor` class. You would need to create your own predictor class that inherits from this base class:\\n\\n```python\\nclass YourCustomPredictor(BaseAPIPredictor):\\n    def __init__(self, function_docs: List[dict], *args, **kwargs):\\n        # Initialize your model/interface here\\n        self.your_interface = YourInterface(*args, **kwargs)\\n        self.function_docs = function_docs\\n\\n    def predict(self, metadata: dict, conversation_history: dict) -> dict:\\n        # Implement your prediction logic here\\n        # Must return a dict with the following structure:\\n        # For API calls:\\n        # {\\n        #     \"role\": \"api\",\\n        #     \"request\": {\\n        #         \"api_name\": \"name_of_api\",\\n        #         \"parameters\": {param_dict}\\n        #     }\\n        # }\\n        # For assistant responses:\\n        # {\\n        #     \"role\": \"assistant\",\\n        #     \"text\": \"response text\"\\n        # }\\n```\\n\\n2. Integration with the Tool Executor:\\nThe `ToolExecutor` class handles the execution of tools and maintains the state. You would use it like this:\\n\\n```python\\n# Initialize the tool executor\\nexecutor = ToolExecutor(init_database_dir=\"path/to/your/databases\")\\n\\n# Create your predictor\\nyour_predictor = YourCustomPredictor(function_docs=your_function_docs)\\n\\n# Run a conversation\\nresults = executor.run_conversation(\\n    conversation=your_conversation_data,\\n    predict_func=your_predictor\\n)\\n```\\n\\n3. Key Components to Implement:\\n\\na. Function Documentation:\\n- Your predictor needs to understand the available tools\\n- Each tool should be documented in a format that your interface can understand\\n- The original implementation uses JSON format for tool definitions\\n\\nb. Conversation Format:\\nYour conversation data should follow this structure:\\n```python\\n{\\n    \"metadata\": {\\n        \"timestamp\": \"YYYY-MM-DD HH:MM:SS\"\\n    },\\n    \"conversation\": [\\n        {\\n            \"role\": \"user\",\\n            \"text\": \"user message\"\\n        },\\n        {\\n            \"role\": \"assistant\",\\n            \"text\": \"assistant response\",\\n            \"apis\": [  # ground truth API calls\\n                {\\n                    \"request\": {\\n                        \"api_name\": \"ToolName\",\\n                        \"parameters\": {...}\\n                    },\\n                    \"response\": {...},\\n                    \"exception\": null\\n                }\\n            ]\\n        }\\n    ]\\n}\\n```\\n\\n4. Handling Tool Execution:\\n- The `ToolExecutor` will handle the actual execution of tools\\n- It maintains state across the conversation\\n- It tracks things like session tokens and database states\\n- It validates predictions against ground truth\\n\\n5. Evaluation:\\nThe system will automatically:\\n- Track successful API calls\\n- Calculate precision and recall\\n- Identify incorrect actions\\n- Provide metrics on the performance\\n\\nTo adapt this to your interface:\\n\\n1. Implement your custom predictor\\n2. Format your tool definitions to match the expected structure\\n3. Format your conversation data according to the specified format\\n4. Use the `ToolExecutor` to run and evaluate conversations\\n\\nThe main adaptations would happen in:\\n- Your predictor implementation\\n- The format of your tool definitions\\n- How you translate between your interface\\'s format and ToolTalk\\'s expected formats\\n\\nThe core evaluation logic can remain unchanged as long as you conform to the expected input/output formats.\\n\\nWould you like me to show you a more detailed example of any of these components?', additional_kwargs={}, response_metadata={'id': 'msg_01XyZb39s94gdxc9Grxm7hnz', 'model': 'claude-3-5-sonnet-20241022', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 9503, 'output_tokens': 882}}, id='run-b96235fe-922e-4471-b5a8-a2778ec3f9fd-0', usage_metadata={'input_tokens': 9503, 'output_tokens': 882, 'total_tokens': 10385, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Tell me how you would adapt this code to a programmatic interface that I defined.\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the code examination, here's how you would adapt ToolTalk to your programmatic interface:\n",
      "\n",
      "1. Create a Custom Predictor:\n",
      "The main integration point is through the `BaseAPIPredictor` class. You would need to create your own predictor class that inherits from this base class:\n",
      "\n",
      "```python\n",
      "class YourCustomPredictor(BaseAPIPredictor):\n",
      "    def __init__(self, function_docs: List[dict], *args, **kwargs):\n",
      "        # Initialize your model/interface here\n",
      "        self.your_interface = YourInterface(*args, **kwargs)\n",
      "        self.function_docs = function_docs\n",
      "\n",
      "    def predict(self, metadata: dict, conversation_history: dict) -> dict:\n",
      "        # Implement your prediction logic here\n",
      "        # Must return a dict with the following structure:\n",
      "        # For API calls:\n",
      "        # {\n",
      "        #     \"role\": \"api\",\n",
      "        #     \"request\": {\n",
      "        #         \"api_name\": \"name_of_api\",\n",
      "        #         \"parameters\": {param_dict}\n",
      "        #     }\n",
      "        # }\n",
      "        # For assistant responses:\n",
      "        # {\n",
      "        #     \"role\": \"assistant\",\n",
      "        #     \"text\": \"response text\"\n",
      "        # }\n",
      "```\n",
      "\n",
      "2. Integration with the Tool Executor:\n",
      "The `ToolExecutor` class handles the execution of tools and maintains the state. You would use it like this:\n",
      "\n",
      "```python\n",
      "# Initialize the tool executor\n",
      "executor = ToolExecutor(init_database_dir=\"path/to/your/databases\")\n",
      "\n",
      "# Create your predictor\n",
      "your_predictor = YourCustomPredictor(function_docs=your_function_docs)\n",
      "\n",
      "# Run a conversation\n",
      "results = executor.run_conversation(\n",
      "    conversation=your_conversation_data,\n",
      "    predict_func=your_predictor\n",
      ")\n",
      "```\n",
      "\n",
      "3. Key Components to Implement:\n",
      "\n",
      "a. Function Documentation:\n",
      "- Your predictor needs to understand the available tools\n",
      "- Each tool should be documented in a format that your interface can understand\n",
      "- The original implementation uses JSON format for tool definitions\n",
      "\n",
      "b. Conversation Format:\n",
      "Your conversation data should follow this structure:\n",
      "```python\n",
      "{\n",
      "    \"metadata\": {\n",
      "        \"timestamp\": \"YYYY-MM-DD HH:MM:SS\"\n",
      "    },\n",
      "    \"conversation\": [\n",
      "        {\n",
      "            \"role\": \"user\",\n",
      "            \"text\": \"user message\"\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"assistant\",\n",
      "            \"text\": \"assistant response\",\n",
      "            \"apis\": [  # ground truth API calls\n",
      "                {\n",
      "                    \"request\": {\n",
      "                        \"api_name\": \"ToolName\",\n",
      "                        \"parameters\": {...}\n",
      "                    },\n",
      "                    \"response\": {...},\n",
      "                    \"exception\": null\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```\n",
      "\n",
      "4. Handling Tool Execution:\n",
      "- The `ToolExecutor` will handle the actual execution of tools\n",
      "- It maintains state across the conversation\n",
      "- It tracks things like session tokens and database states\n",
      "- It validates predictions against ground truth\n",
      "\n",
      "5. Evaluation:\n",
      "The system will automatically:\n",
      "- Track successful API calls\n",
      "- Calculate precision and recall\n",
      "- Identify incorrect actions\n",
      "- Provide metrics on the performance\n",
      "\n",
      "To adapt this to your interface:\n",
      "\n",
      "1. Implement your custom predictor\n",
      "2. Format your tool definitions to match the expected structure\n",
      "3. Format your conversation data according to the specified format\n",
      "4. Use the `ToolExecutor` to run and evaluate conversations\n",
      "\n",
      "The main adaptations would happen in:\n",
      "- Your predictor implementation\n",
      "- The format of your tool definitions\n",
      "- How you translate between your interface's format and ToolTalk's expected formats\n",
      "\n",
      "The core evaluation logic can remain unchanged as long as you conform to the expected input/output formats.\n",
      "\n",
      "Would you like me to show you a more detailed example of any of these components?\n"
     ]
    }
   ],
   "source": [
    "print(chunk['agent']['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add pydantic dependency to the project\n",
      "Project directory: /Users/khannguyen/projects/evaluations/ToolTalk \n",
      "{'agent': {'messages': [AIMessage(content=[{'text': \"I'll help you add the pydantic dependency to the project. First, let me check if there's a requirements.txt or pyproject.toml file in the project directory.\", 'type': 'text'}, {'id': 'toolu_01FNys8PKqVGMgVUzD8RUsiy', 'input': {'directory': '/Users/khannguyen/projects/evaluations/ToolTalk'}, 'name': 'DirectoryMapperTool', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01PmcAE6jPeArUeHmCvEFsYh', 'model': 'claude-3-5-sonnet-20241022', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 1551, 'output_tokens': 111}}, id='run-f9f0ff36-0128-4efd-abda-93290c95ab8f-0', tool_calls=[{'name': 'DirectoryMapperTool', 'args': {'directory': '/Users/khannguyen/projects/evaluations/ToolTalk'}, 'id': 'toolu_01FNys8PKqVGMgVUzD8RUsiy', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1551, 'output_tokens': 111, 'total_tokens': 1662, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='ToolTalk/\\n├── CODE_OF_CONDUCT.md\\n├── CONTRIBUTING.md\\n├── LICENSE\\n├── NOTICE\\n├── README.md\\n├── SECURITY.md\\n├── SUPPORT.md\\n├── data/\\n│   ├── databases/\\n│   │   ├── Account.json\\n│   │   ├── Alarm.json\\n│   │   ├── Calendar.json\\n│   │   ├── Email.json\\n│   │   ├── HistoricWeather.json\\n│   │   ├── Message.json\\n│   │   ├── Reminder.json\\n│   │   └── Weather.json\\n│   ├── easy/\\n│   │   ├── AddAlarm-easy.json\\n│   │   ├── AddReminder-easy.json\\n│   │   ├── ChangePassword-easy.json\\n│   │   ├── CompleteReminder-easy.json\\n│   │   ├── CreateEvent-easy.json\\n│   │   ├── CurrentWeather-easy.json\\n│   │   ├── DeleteAccount-easy.json\\n│   │   ├── DeleteAlarm-easy.json\\n│   │   ├── DeleteEvent-easy.json\\n│   │   ├── DeleteReminder-easy.json\\n│   │   ├── FindAlarms-easy.json\\n│   │   ├── ForecastWeather-easy.json\\n│   │   ├── GetAccountInformation-easy.json\\n│   │   ├── GetReminders-easy.json\\n│   │   ├── HistoricWeather-easy.json\\n│   │   ├── LogoutUser-easy.json\\n│   │   ├── ModifyEvent-easy.json\\n│   │   ├── QueryCalendar-easy.json\\n│   │   ├── QueryUser-easy.json\\n│   │   ├── RegisterUser-easy.json\\n│   │   ├── ResetPassword-easy.json\\n│   │   ├── SearchInbox-easy.json\\n│   │   ├── SearchMessages-easy.json\\n│   │   ├── SendEmail-easy.json\\n│   │   ├── SendMessage-easy.json\\n│   │   ├── SendVerificationCode-easy.json\\n│   │   ├── UpdateAccountInformation-easy.json\\n│   │   └── UserLogin-easy.json\\n│   └── tooltalk/\\n│       ├── AccountTools-Alarm-Calendar-AddAlarm-0.json\\n│       ├── AccountTools-Alarm-Email-GetAccountInformati-0.json\\n│       ├── AccountTools-Alarm-Messages-FindAlarm-0.json\\n│       ├── AccountTools-Alarm-Weather-DeleteAccount-2.json\\n│       ├── AccountTools-Calendar-Weather-RegisterUser-0.json\\n│       ├── AccountTools-Email-Reminder-ChangePassword-1.json\\n│       ├── Alarm-Calendar-Email-DeleteAlarm-1.json\\n│       ├── Alarm-Calendar-Messages-AddAlarm-1.json\\n│       ├── Alarm-Messages-Reminder-GetReminder-2.json\\n│       ├── Alarm-Reminder-Weather-AddReminder-1.json\\n│       ├── Alarm-Reminder-Weather-DeleteAlarm-2.json\\n│       ├── Alarm-Reminder-Weather-FindAlarm-2.json\\n│       ├── Calendar-Email-Reminder-GetReminder-1.json\\n│       ├── Calendar-Email-Reminder-SendEmail-2.json\\n│       ├── Calendar-Messages-Reminder-AddReminder-1.json\\n│       ├── Calendar-Messages-Reminder-CreateEvent-1.json\\n│       ├── Calendar-Messages-Reminder-ModifyEvent-0.json\\n│       ├── Calendar-Messages-Reminder-QueryCalendar-2.json\\n│       ├── Calendar-Messages-Weather-DeleteEvent-0.json\\n│       ├── Calendar-Messages-Weather-SendMessage-0.json\\n│       ├── Calendar-Messages-Weather-SendMessage-1.json\\n│       ├── Calendar-Reminder-Weather-CompleteReminder-1.json\\n│       ├── Calendar-Reminder-Weather-CreateEvent-1.json\\n│       ├── Calendar-Reminder-Weather-DeleteEvent-0.json\\n│       ├── Calendar-Reminder-Weather-DeleteReminder-1.json\\n│       ├── Calendar-Reminder-Weather-ModifyEvent-0.json\\n│       ├── Calendar-Reminder-Weather-ModifyEvent-1.json\\n│       ├── Calendar-Reminder-Weather-QueryCalendar-0.json\\n│       ├── Email-Messages-Reminder-DeleteReminder-1.json\\n│       ├── Email-Messages-Reminder-SearchMessage-1.json\\n│       ├── Email-Messages-Reminder-SendEmail-2.json\\n│       ├── Email-Messages-Reminder-SendMessage-2.json\\n│       ├── Email-Messages-Weather-SendMessage-2.json\\n│       ├── Email-Reminder-Weather-CompleteReminder-2.json\\n│       ├── Email-Reminder-Weather-DeleteReminder-0.json\\n│       ├── Email-Reminder-Weather-GetReminder-0.json\\n│       ├── Email-Reminder-Weather-SearchInbox-1.json\\n│       ├── Email-Reminder-Weather-SendEmail-2.json\\n│       ├── Messages-Reminder-Weather-AddReminder-1.json\\n│       ├── Messages-Reminder-Weather-CompleteReminder-1.json\\n│       ├── Messages-Reminder-Weather-ForecastWeather-1.json\\n│       ├── Messages-Reminder-Weather-GetReminder-0.json\\n│       ├── Messages-Reminder-Weather-SearchMessage-2.json\\n│       ├── Messages-Reminder-Weather-SendMessage-2.json\\n│       ├── golden_conversation_1.json\\n│       ├── golden_conversation_2.json\\n│       ├── golden_conversation_3.json\\n│       ├── golden_conversation_4.json\\n│       ├── golden_conversation_5.json\\n│       └── golden_conversation_6.json\\n├── images/\\n│   └── Evaluation.png\\n├── output/\\n│   └── nvdev/\\n│       └── meta/\\n│           ├── llama-3.1-70b-instruct/\\n│           │   ├── AddAlarm-easy.json\\n│           │   ├── AddReminder-easy.json\\n│           │   ├── ChangePassword-easy.json\\n│           │   ├── CompleteReminder-easy.json\\n│           │   ├── CreateEvent-easy.json\\n│           │   ├── CurrentWeather-easy.json\\n│           │   ├── DeleteAccount-easy.json\\n│           │   ├── DeleteAlarm-easy.json\\n│           │   ├── DeleteEvent-easy.json\\n│           │   ├── DeleteReminder-easy.json\\n│           │   ├── FindAlarms-easy.json\\n│           │   ├── ForecastWeather-easy.json\\n│           │   ├── GetAccountInformation-easy.json\\n│           │   ├── GetReminders-easy.json\\n│           │   ├── HistoricWeather-easy.json\\n│           │   ├── LogoutUser-easy.json\\n│           │   ├── ModifyEvent-easy.json\\n│           │   ├── QueryCalendar-easy.json\\n│           │   ├── QueryUser-easy.json\\n│           │   ├── RegisterUser-easy.json\\n│           │   ├── ResetPassword-easy.json\\n│           │   ├── SearchInbox-easy.json\\n│           │   ├── SearchMessages-easy.json\\n│           │   ├── SendEmail-easy.json\\n│           │   ├── SendMessage-easy.json\\n│           │   ├── SendVerificationCode-easy.json\\n│           │   ├── UpdateAccountInformation-easy.json\\n│           │   ├── UserLogin-easy.json\\n│           │   └── metrics.json\\n│           └── llama-3.1-70b-instruct2/\\n├── requirements.txt\\n├── scripts/\\n│   ├── evaluate_gpt35turbo.sh\\n│   └── evaluate_gpt4.sh\\n├── setup.cfg\\n├── setup.py\\n├── src/\\n│   ├── __init__.py\\n│   ├── prompts/\\n│   │   └── scenario_template.md\\n│   ├── scripts/\\n│   │   ├── fix_apis_used.py\\n│   │   └── refactor_tool_talk.py\\n│   ├── tooltalk/\\n│   │   ├── __init__.py\\n│   │   ├── __pycache__/\\n│   │   │   └── __init__.cpython-312.pyc\\n│   │   ├── apis/\\n│   │   │   ├── __init__.py\\n│   │   │   ├── __pycache__/\\n│   │   │   │   ├── __init__.cpython-312.pyc\\n│   │   │   │   ├── account.cpython-312.pyc\\n│   │   │   │   ├── alarm.cpython-312.pyc\\n│   │   │   │   ├── api.cpython-312.pyc\\n│   │   │   │   ├── calendar.cpython-312.pyc\\n│   │   │   │   ├── email.cpython-312.pyc\\n│   │   │   │   ├── exceptions.cpython-312.pyc\\n│   │   │   │   ├── message.cpython-312.pyc\\n│   │   │   │   ├── reminder.cpython-312.pyc\\n│   │   │   │   ├── utils.cpython-312.pyc\\n│   │   │   │   └── weather.cpython-312.pyc\\n│   │   │   ├── account.py\\n│   │   │   ├── alarm.py\\n│   │   │   ├── api.py\\n│   │   │   ├── calendar.py\\n│   │   │   ├── email.py\\n│   │   │   ├── exceptions.py\\n│   │   │   ├── message.py\\n│   │   │   ├── reminder.py\\n│   │   │   ├── utils.py\\n│   │   │   └── weather.py\\n│   │   ├── evaluation/\\n│   │   │   ├── __init__.py\\n│   │   │   ├── __pycache__/\\n│   │   │   │   ├── __init__.cpython-312.pyc\\n│   │   │   │   └── tool_executor.cpython-312.pyc\\n│   │   │   ├── calculate_error_types.py\\n│   │   │   ├── evaluate_nim.py\\n│   │   │   ├── evaluate_openai.py\\n│   │   │   └── tool_executor.py\\n│   │   ├── generation/\\n│   │   │   ├── __init__.py\\n│   │   │   └── scenario_generator.py\\n│   │   ├── llm_clients/\\n│   │   └── utils/\\n│   │       ├── __init__.py\\n│   │       ├── __pycache__/\\n│   │       │   ├── __init__.cpython-312.pyc\\n│   │       │   ├── file_utils.cpython-312.pyc\\n│   │       │   └── openai_utils.cpython-312.pyc\\n│   │       ├── file_utils.py\\n│   │       └── openai_utils.py\\n│   └── tooltalk.egg-info/\\n│       ├── PKG-INFO\\n│       ├── SOURCES.txt\\n│       ├── dependency_links.txt\\n│       ├── requires.txt\\n│       └── top_level.txt\\n└── tests/\\n    ├── __pycache__/\\n    │   ├── test_documentation.cpython-312-pytest-7.4.4.pyc\\n    │   ├── test_documentation.cpython-312-pytest-8.3.4.pyc\\n    │   ├── test_oracle.cpython-312-pytest-7.4.4.pyc\\n    │   └── test_oracle.cpython-312-pytest-8.3.4.pyc\\n    ├── test_documentation.py\\n    └── test_oracle.py', name='DirectoryMapperTool', id='69eb9b57-05e7-46b1-8df0-7fb875388465', tool_call_id='toolu_01FNys8PKqVGMgVUzD8RUsiy')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content=[{'text': \"I see there's a requirements.txt file in the project root directory. Let me check its current contents first.\", 'type': 'text'}, {'id': 'toolu_01K5yN8iWoibgc7M2hM6ei5h', 'input': {'file_path': '/Users/khannguyen/projects/evaluations/ToolTalk/requirements.txt'}, 'name': 'FileReaderTool', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01Xnp9KxrP9jnRYaNeddXbeN', 'model': 'claude-3-5-sonnet-20241022', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 4824, 'output_tokens': 102}}, id='run-3a000d0a-59e5-4c88-93bf-b01450c7ef0d-0', tool_calls=[{'name': 'FileReaderTool', 'args': {'file_path': '/Users/khannguyen/projects/evaluations/ToolTalk/requirements.txt'}, 'id': 'toolu_01K5yN8iWoibgc7M2hM6ei5h', 'type': 'tool_call'}], usage_metadata={'input_tokens': 4824, 'output_tokens': 102, 'total_tokens': 4926, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='1: tqdm\\n2: numpy\\n3: matplotlib\\n4: openai\\n5: sent2vec\\n6: jupyterlab\\n7: pytest', name='FileReaderTool', id='0b90195c-3335-4b75-93e1-df982a558048', tool_call_id='toolu_01K5yN8iWoibgc7M2hM6ei5h')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content=[{'text': \"Now I'll add the pydantic dependency to the requirements.txt file. I'll use the FileEditorTool to insert pydantic at the end of the file.\", 'type': 'text'}, {'id': 'toolu_0119DhfHpgZGhkUqjv2F92gu', 'input': {'file_path': '/Users/khannguyen/projects/evaluations/ToolTalk/requirements.txt', 'action': 'insert', 'content': 'pydantic'}, 'name': 'FileEditorTool', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01FbTh2p2E53pmQYRd3hdDeM', 'model': 'claude-3-5-sonnet-20241022', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 4971, 'output_tokens': 152}}, id='run-b6e07fa3-7b79-4e88-9ecc-3a12ec5ebaf0-0', tool_calls=[{'name': 'FileEditorTool', 'args': {'file_path': '/Users/khannguyen/projects/evaluations/ToolTalk/requirements.txt', 'action': 'insert', 'content': 'pydantic'}, 'id': 'toolu_0119DhfHpgZGhkUqjv2F92gu', 'type': 'tool_call'}], usage_metadata={'input_tokens': 4971, 'output_tokens': 152, 'total_tokens': 5123, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content=\"Successfully inserted content into file '/Users/khannguyen/projects/evaluations/ToolTalk/requirements.txt' at line 8.\", name='FileEditorTool', id='a33f3bd3-9012-4b86-8253-b69d7e9502cd', tool_call_id='toolu_0119DhfHpgZGhkUqjv2F92gu')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content=\"I've added pydantic to your requirements.txt file. You can now install it by running:\\n```bash\\npip install -r requirements.txt\\n```\\n\\nIs there anything else you need help with?\", additional_kwargs={}, response_metadata={'id': 'msg_01RXYpuHxVTPAGXMShwUm81j', 'model': 'claude-3-5-sonnet-20241022', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 5165, 'output_tokens': 48}}, id='run-28b1b839-3dcf-444e-b611-966358cc7f56-0', usage_metadata={'input_tokens': 5165, 'output_tokens': 48, 'total_tokens': 5213, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, TypedDict, Annotated, Sequence\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from agent_coding_template.tools import *\n",
    "\n",
    "# Define state schema\n",
    "class AgentState(TypedDict):\n",
    "    messages: Sequence[HumanMessage]\n",
    "    thread_id: str\n",
    "\n",
    "# Create tools and model\n",
    "model = ChatAnthropic(model_name=\"claude-3-5-sonnet-20241022\")\n",
    "tools = [DirectoryMapperTool(), FileReaderTool(), ReadmeReaderTool(), FileEditorTool()]\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "system_prompt = \"\"\"**Code Assistant Protocol**\n",
    "\n",
    "You are an advanced code editing assistant.\n",
    "\n",
    "**File Editing Protocol** (MUST FOLLOW when making changes):\n",
    "1. **Pre-Edit Verification** - ALWAYS use FileReaderTool to:\n",
    "   - Cross-validate paths using DirectoryMapperTool\n",
    "   - Get current file state WITH LINE NUMBERS\n",
    "   - Verify exact location for modifications\n",
    "   \n",
    "2. **Modification Rules**:\n",
    "   - Use FileEditorTool to make changes to the file.\n",
    "   - NEVER assume line numbers - ALWAYS verify via FileReaderTool\n",
    "   - NEVER include unchanged content - only send NEW/CHANGED lines\n",
    "   - Example: To add 1 line at position 42:\n",
    "     ✅ Correct: insert at line 42 with content\n",
    "     ❌ Wrong: Rewriting entire file with new line added\n",
    "\n",
    "**Token Efficiency Guidelines**:\n",
    "- Use precise parameters in ALL tool calls to avoid unnecessary tokens\n",
    "\n",
    "**General Operational Guidelines**:\n",
    "- Ask clarification questions if requirements are ambiguous\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "agent = create_react_agent(model, tools, checkpointer=memory, prompt=system_prompt)\n",
    "\n",
    "# Load the template file\n",
    "template = env.get_template(\"repo_prompt_template.j2\")\n",
    "content = template.render(repo_dir=\"/Users/khannguyen/projects/evaluations/ToolTalk\")\n",
    "print(content)\n",
    "\n",
    "# Stream results\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [HumanMessage(content=content)]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent-coding-template",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
